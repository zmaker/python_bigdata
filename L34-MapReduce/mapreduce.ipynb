{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce e Hadoop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce è un paradigma di programmazione per l'elaborazione dei big data, in cui i dati vengono partizionati in pezzi distribuiti e trattati da una serie di trasformazioni.\n",
    "\n",
    "Il paradigma di programmazione MapReduce elabora i dati in 2 operazioni: map() e poi reduce(). map() è una funzione definita dall'utente che mappa ciascun record di dati nella raccolta di dati. reduce() raggruppa l'output di map() con un'altra funzione definita dall'utente.\n",
    "\n",
    "MapReduce opera su coppie (chiave, valore).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop\n",
    "\n",
    "Hadoop è un framework open-source progettato per l'elaborazione e l'archiviazione di grandi volumi di dati in modo distribuito e scalabile. È stato sviluppato da Apache e si basa su un'architettura di tipo \"cluster\". Ecco alcuni punti chiave riguardanti Hadoop:\n",
    "\n",
    "## 1. Componenti Principali\n",
    "\n",
    "- **Hadoop Distributed File System (HDFS)**: Un sistema di file distribuito progettato per memorizzare grandi file su cluster di computer. HDFS suddivide i file in blocchi di dimensioni fisse e li distribuisce su più nodi del cluster, garantendo tolleranza ai guasti.\n",
    "  \n",
    "- **MapReduce**: Un modello di programmazione per l'elaborazione parallela di dati. Le applicazioni MapReduce sono suddivise in due fasi principali: `map()`, che elabora i dati in input e genera coppie chiave-valore, e `reduce()`, che aggrega i risultati delle operazioni `map()`.\n",
    "  \n",
    "- **YARN (Yet Another Resource Negotiator)**: Un sistema di gestione delle risorse che consente di gestire e pianificare l'esecuzione delle applicazioni su un cluster Hadoop. YARN separa le funzioni di gestione delle risorse e di scheduling da quelle di elaborazione dei dati.\n",
    "\n",
    "## 2. Scalabilità\n",
    "\n",
    "Hadoop è progettato per scalare orizzontalmente, il che significa che puoi semplicemente aggiungere più nodi al cluster per gestire un volume maggiore di dati. Può gestire petabyte di dati su migliaia di nodi.\n",
    "\n",
    "## 3. Tolleranza ai Guasti\n",
    "\n",
    "HDFS e il modello MapReduce sono progettati per essere resilienti ai guasti. Se un nodo nel cluster si guasta, Hadoop può automaticamente ridistribuire i compiti e i dati su altri nodi.\n",
    "\n",
    "## 4. Elaborazione dei Dati\n",
    "\n",
    "Hadoop è particolarmente adatto per l'elaborazione di grandi volumi di dati non strutturati e semi-strutturati, rendendolo una scelta comune per analisi di big data, data warehousing, machine learning e altre applicazioni di data analytics.\n",
    "\n",
    "## 5. Ecosistema Hadoop\n",
    "\n",
    "Hadoop è spesso utilizzato insieme a una serie di altri strumenti e tecnologie, come:\n",
    "- **Apache Hive** (per l'analisi dei dati con SQL)\n",
    "- **Apache Pig** (per l'elaborazione dei dati)\n",
    "- **Apache HBase** (un database NoSQL)\n",
    "- **Apache Spark** (per l'elaborazione in-memory)\n",
    "\n",
    "## 6. Applicazioni\n",
    "\n",
    "Le aziende utilizzano Hadoop per una varietà di applicazioni, tra cui:\n",
    "- Analisi dei dati\n",
    "- Monitoraggio dei log\n",
    "- Raccomandazioni di prodotti\n",
    "- Rilevamento di frodi\n",
    "- E molto altro.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MrJob \n",
    "**mrjob** è una libreria che consente di scrivere programmi Python che girano su Hadoop. Con mrjob, puoi testare il tuo codice localmente senza installare Hadoop o eseguirlo su un cluster a tua scelta. \"Se non vuoi diventare un esperto di Hadoop ma hai bisogno della potenza di calcolo di MapReduce, mrjob potrebbe essere proprio quello che fa per te.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
    "\n",
    "https://medium.com/@guillermovc/setting-up-hadoop-with-docker-and-using-mapreduce-framework-c1cd125d4f7b\n",
    "\n",
    "https://www.youtube.com/watch?v=GCeb0qhnais\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
